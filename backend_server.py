"""
Driver Behavior Detection Backend API Server
- ë‹¤ì¤‘ ì‚¬ìš©ì ì§€ì› (ì„¸ì…˜ë³„ ë²„í¼ ê´€ë¦¬)
- ë°°ì¹˜ ì¶”ë¡ ìœ¼ë¡œ GPU íš¨ìœ¨ ìµœëŒ€í™”
- WebSocketìœ¼ë¡œ ì‹¤ì‹œê°„ í†µì‹ 
- SQLite ê¸°ë°˜ ì‚¬ìš©ì ì¸ì¦ (ì‹œì—°ìš©)
- GPU ìƒì‹œ ëŒ€ê¸° + ì¦‰ì‹œ ë°°ì¹˜ ì²˜ë¦¬
"""
import os
import sys
import json
import base64
import asyncio
import numpy as np
import torch
import time
import uuid
import sqlite3
from collections import defaultdict
from io import BytesIO
from fastapi import FastAPI, HTTPException, WebSocket, WebSocketDisconnect
from fastapi.middleware.cors import CORSMiddleware
from fastapi.staticfiles import StaticFiles
from fastapi.responses import FileResponse
from pydantic import BaseModel
from typing import Optional, Dict, Any, List
import uvicorn
import threading
from queue import Queue, Empty
from dataclasses import dataclass

# ëª¨ë¸ ë¡œë“œ
sys.path.insert(0, '/root/Driver_monitoring')
from model import DriverBehaviorModel

# í´ë˜ìŠ¤ ì •ì˜
CLASS_NAMES = {
    0: "Normal",
    1: "Drowsy",
    2: "Searching",
    3: "Phone",
    4: "Assault"
}

# ì „ì—­ ë³€ìˆ˜
model = None
device = None
preallocated_buffer = None  # GPU ë©”ëª¨ë¦¬ ì‚¬ì „ í™•ë³´ìš©

# GPU ì •ê·œí™” ìƒìˆ˜ (CUDA í…ì„œ)
gpu_mean = None
gpu_std = None

# ë‹¤ì¤‘ ì‚¬ìš©ì ì„¸ì…˜ ê´€ë¦¬
user_sessions: Dict[str, Dict] = {}
sessions_lock = threading.Lock()

# ë°°ì¹˜ ì¶”ë¡  ì„¤ì •
BATCH_SIZE = 16  # RTX 4000 Ada 20GB - ë” í° ë°°ì¹˜ë¡œ ì²˜ë¦¬ëŸ‰ í–¥ìƒ
FRAMES_PER_INFERENCE = 30
FRAME_BUFFER_SIZE = 60  # ë²„í¼ í¬ê¸° (60í”„ë ˆì„ ëª¨ìœ¼ê³ )
FRAME_SHIFT = 10  # ì¶”ë¡  í›„ ì‹œí”„íŠ¸ëŸ‰ (10í”„ë ˆì„ì”© ì´ë™ = 33% ìƒˆ ë°ì´í„°)
BATCH_TIMEOUT = 0.05  # 50ms - ë°°ì¹˜ê°€ ì•ˆ ì°¨ë„ ì´ ì‹œê°„ í›„ì— ì²˜ë¦¬

# ì¶”ë¡  í (ì¦‰ì‹œ ì²˜ë¦¬ìš©)
@dataclass
class InferenceJob:
    session_id: str
    frames: List[np.ndarray]
    websocket: Optional[any] = None
    timestamp: float = 0.0

inference_queue: Queue = Queue()
results_store: Dict[str, Dict] = {}  # HTTP í´ë§ìš© ê²°ê³¼ ì €ì¥

# ë””ë²„ê·¸ìš© í”„ë ˆì„ ì €ì¥
DEBUG_DIR = "/tmp/inference_debug"
os.makedirs(DEBUG_DIR, exist_ok=True)
inference_history: List[Dict] = []  # ìµœê·¼ ì¶”ë¡  ê¸°ë¡ (ìµœëŒ€ 100ê°œ)
SAVE_DEBUG_FRAMES = True  # ë””ë²„ê·¸ í”„ë ˆì„ ì €ì¥ ì—¬ë¶€

# SQLite DB ì„¤ì •
DB_PATH = '/root/users.db'

def init_database():
    """SQLite ë°ì´í„°ë² ì´ìŠ¤ ì´ˆê¸°í™”"""
    conn = sqlite3.connect(DB_PATH)
    cursor = conn.cursor()

    # ì‚¬ìš©ì í…Œì´ë¸”
    cursor.execute('''
        CREATE TABLE IF NOT EXISTS users (
            id TEXT PRIMARY KEY,
            name TEXT NOT NULL,
            password TEXT NOT NULL,
            address TEXT,
            region_name TEXT,
            region_campaign TEXT,
            region_target INTEGER DEFAULT 90,
            region_reward TEXT,
            score INTEGER DEFAULT 80,
            discount_rate INTEGER DEFAULT 0,
            created_at TEXT
        )
    ''')

    # ìš´ì „ ê¸°ë¡ í…Œì´ë¸” (ì„¸ì…˜ ì •ë³´)
    cursor.execute('''
        CREATE TABLE IF NOT EXISTS driving_logs (
            id INTEGER PRIMARY KEY AUTOINCREMENT,
            user_id TEXT NOT NULL,
            start_time TEXT NOT NULL,
            end_time TEXT,
            status TEXT DEFAULT 'driving',
            total_detections INTEGER DEFAULT 0,
            normal_count INTEGER DEFAULT 0,
            drowsy_count INTEGER DEFAULT 0,
            searching_count INTEGER DEFAULT 0,
            phone_count INTEGER DEFAULT 0,
            assault_count INTEGER DEFAULT 0,
            FOREIGN KEY (user_id) REFERENCES users(id)
        )
    ''')

    # ê°œë³„ ê°ì§€ ê¸°ë¡ í…Œì´ë¸”
    cursor.execute('''
        CREATE TABLE IF NOT EXISTS driving_detections (
            id INTEGER PRIMARY KEY AUTOINCREMENT,
            driving_log_id INTEGER NOT NULL,
            detected_at TEXT NOT NULL,
            class_id INTEGER NOT NULL,
            class_name TEXT NOT NULL,
            confidence REAL NOT NULL,
            FOREIGN KEY (driving_log_id) REFERENCES driving_logs(id)
        )
    ''')

    conn.commit()
    conn.close()
    print("Database initialized!")

def get_db_connection():
    conn = sqlite3.connect(DB_PATH)
    conn.row_factory = sqlite3.Row
    return conn

def load_model():
    """ëª¨ë¸ ë¡œë“œ ë° GPU ì›Œë°ì—… + ë©”ëª¨ë¦¬ ì‚¬ì „ í™•ë³´"""
    global model, device, preallocated_buffer, gpu_mean, gpu_std

    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
    print(f"Using device: {device}")

    # GPU ì •ê·œí™” ìƒìˆ˜ ì´ˆê¸°í™”
    gpu_mean = torch.tensor([0.485, 0.456, 0.406], device=device).view(1, 3, 1, 1)
    gpu_std = torch.tensor([0.229, 0.224, 0.225], device=device).view(1, 3, 1, 1)

    if torch.cuda.is_available():
        gpu_mem = torch.cuda.get_device_properties(0).total_memory / 1024**3
        print(f"GPU Memory: {gpu_mem:.1f} GB")

    model = DriverBehaviorModel(num_classes=5, pretrained=False)
    checkpoint = torch.load('/root/Driver_monitoring/pytorch_model.bin',
                           map_location='cpu', weights_only=True)
    # ìƒˆ í˜•ì‹: {'model': state_dict} / êµ¬ í˜•ì‹: state_dict ì§ì ‘
    state_dict = checkpoint.get('model', checkpoint) if isinstance(checkpoint, dict) else checkpoint
    model.load_state_dict(state_dict)
    model = model.to(device)
    model.eval()

    # GPU ì›Œë°ì—… - ìµœëŒ€ ë°°ì¹˜ë¡œ ë”ë¯¸ ì¶”ë¡ 
    print("Warming up GPU with max batch...")
    with torch.no_grad():
        dummy_input = torch.randn(BATCH_SIZE, 3, 30, 224, 224).to(device)
        for _ in range(5):  # ë” ë§ì´ ì›Œë°ì—…
            _ = model(dummy_input)
        torch.cuda.synchronize()

    # GPU ë©”ëª¨ë¦¬ ì‚¬ì „ í™•ë³´ - ì‹¤ì œ ì¶”ë¡ ì„ ì—¬ëŸ¬ ë²ˆ ìˆ˜í–‰í•´ì„œ ë©”ëª¨ë¦¬ í’€ í™•ì¥
    print("Pre-allocating GPU memory for max throughput...")

    # ì‹¤ì œ max batch ì¶”ë¡ ì„ ì—¬ëŸ¬ ë²ˆ ìˆ˜í–‰í•˜ì—¬ CUDA ë©”ëª¨ë¦¬ í’€ í™•ì¥
    with torch.no_grad():
        for i in range(10):
            test_input = torch.randn(BATCH_SIZE, 3, 30, 224, 224, device=device)
            _ = model(test_input)
            torch.cuda.synchronize()

    # ë©”ëª¨ë¦¬ ìƒíƒœ ì¶œë ¥
    if torch.cuda.is_available():
        allocated = torch.cuda.memory_allocated() / 1024**3
        reserved = torch.cuda.memory_reserved() / 1024**3
        max_allocated = torch.cuda.max_memory_allocated() / 1024**3
        print(f"GPU Memory - Current: {allocated:.2f} GB, Reserved: {reserved:.2f} GB, Peak: {max_allocated:.2f} GB")

    # ì…ë ¥ ë²„í¼ ìœ ì§€ (GC ë°©ì§€)
    preallocated_buffer = {
        'input': torch.zeros(BATCH_SIZE, 3, 30, 224, 224, device=device),
    }
    torch.cuda.synchronize()

    print(f"Model ready! Max batch size: {BATCH_SIZE}")
    return model

# FastAPI ì•±
app = FastAPI(title="Driver Behavior Detection API")

app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# ìš”ì²­ ëª¨ë¸
class InferRequest(BaseModel):
    session_id: str
    image: str

class SignUpRequest(BaseModel):
    id: str
    name: str
    password: str
    address: Optional[str] = None
    region_name: Optional[str] = "ì „êµ­ ê³µí†µ"
    region_campaign: Optional[str] = "ëŒ€í•œë¯¼êµ­ ì•ˆì „ìš´ì „ ì±Œë¦°ì§€"
    region_target: Optional[int] = 90
    region_reward: Optional[str] = "ì•ˆì „ìš´ì „ ì¸ì¦ì„œ ë°œê¸‰"

class LoginRequest(BaseModel):
    id: str
    password: str

class StartDrivingRequest(BaseModel):
    user_id: str

class EndDrivingRequest(BaseModel):
    driving_log_id: int

class SaveDetectionRequest(BaseModel):
    driving_log_id: int
    class_id: int
    class_name: str
    confidence: float

# í™œì„± ìš´ì „ ì„¸ì…˜ ë§¤í•‘ (session_id -> driving_log_id)
active_driving_logs: Dict[str, int] = {}

def preprocess_image(base64_image: str) -> np.ndarray:
    """Base64 ì´ë¯¸ì§€ ë””ì½”ë”© + ë¦¬ì‚¬ì´ì¦ˆ (ì •ê·œí™”ëŠ” GPUì—ì„œ)"""
    import cv2

    if ',' in base64_image:
        base64_image = base64_image.split(',')[1]

    image_bytes = base64.b64decode(base64_image)
    nparr = np.frombuffer(image_bytes, np.uint8)
    img = cv2.imdecode(nparr, cv2.IMREAD_COLOR)

    if img is None:
        raise ValueError("Failed to decode image")

    if img.shape[:2] != (224, 224):
        img = cv2.resize(img, (224, 224), interpolation=cv2.INTER_LINEAR)

    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)
    return img  # uint8 [224, 224, 3] - ì •ê·œí™”ëŠ” GPUì—ì„œ

def run_batch_inference(jobs: List[InferenceJob]) -> List[Dict[str, Any]]:
    """ë°°ì¹˜ ì¶”ë¡  ì‹¤í–‰ - GPUì—ì„œ ì „ì²˜ë¦¬ + ì¶”ë¡ """
    global model, device, gpu_mean, gpu_std

    if not jobs:
        return []

    batch_size = len(jobs)

    # ë°°ì¹˜ í…ì„œ êµ¬ì„± (uint8 â†’ GPUë¡œ ì§ì ‘ ì „ì†¡)
    batch_tensors = []
    for job in jobs:
        frames_array = np.stack(job.frames, axis=0)  # [30, 224, 224, 3] uint8
        frames_array = frames_array.transpose(3, 0, 1, 2)  # [3, 30, 224, 224]
        batch_tensors.append(frames_array)

    # GPUë¡œ ì „ì†¡ í›„ ì •ê·œí™” (ë” ë¹ ë¦„)
    input_tensor = torch.from_numpy(np.stack(batch_tensors, axis=0)).to(device, dtype=torch.float32)
    input_tensor = input_tensor / 255.0  # GPUì—ì„œ ìŠ¤ì¼€ì¼ë§
    # [B, 3, 30, 224, 224] í˜•íƒœë¡œ ì •ê·œí™” (mean/stdëŠ” [1, 3, 1, 1])
    input_tensor = (input_tensor - gpu_mean.unsqueeze(2)) / gpu_std.unsqueeze(2)

    with torch.no_grad():
        output = model(input_tensor)
        probabilities = torch.softmax(output, dim=1)
        predicted_classes = torch.argmax(probabilities, dim=1)

    results = []
    for i in range(batch_size):
        pred_class = predicted_classes[i].item()
        confidence = probabilities[i][pred_class].item()
        results.append({
            "class_id": pred_class,
            "class_name": CLASS_NAMES[pred_class],
            "confidence": round(confidence * 100, 2),
            "probabilities": {
                CLASS_NAMES[j]: round(probabilities[i][j].item() * 100, 2)
                for j in range(5)
            }
        })

    return results

# GPU ìƒì‹œ ëŒ€ê¸° ë°°ì¹˜ ì›Œì»¤
def gpu_batch_worker():
    """GPUì—ì„œ ìƒì‹œ ëŒ€ê¸°í•˜ë©° ìš”ì²­ ì¦‰ì‹œ ë°°ì¹˜ ì²˜ë¦¬"""
    print("GPU batch worker started - waiting for requests...")

    while True:
        jobs = []
        start_time = time.time()

        # ì²« ë²ˆì§¸ ì‘ì—… ëŒ€ê¸° (ë¸”ë¡œí‚¹)
        try:
            first_job = inference_queue.get(timeout=1.0)
            jobs.append(first_job)
        except Empty:
            continue  # íƒ€ì„ì•„ì›ƒ, ë‹¤ì‹œ ëŒ€ê¸°

        # ë°°ì¹˜ ì±„ìš°ê¸° (BATCH_TIMEOUT ë‚´ì— ë” ëª¨ìœ¼ê¸°)
        while len(jobs) < BATCH_SIZE:
            elapsed = time.time() - start_time
            remaining = BATCH_TIMEOUT - elapsed

            if remaining <= 0:
                break

            try:
                job = inference_queue.get(timeout=remaining)
                jobs.append(job)
            except Empty:
                break

        # ë°°ì¹˜ ì¶”ë¡  ì‹¤í–‰
        if jobs:
            try:
                inference_start = time.time()
                results = run_batch_inference(jobs)
                inference_time = (time.time() - inference_start) * 1000

                # ì¶”ë¡  ê²°ê³¼ ë¡œê·¸ ì¶œë ¥ + ë””ë²„ê·¸ ì €ì¥
                for i, result in enumerate(results):
                    print(f"ğŸ¯ ì¶”ë¡ ê²°ê³¼ [{jobs[i].session_id[:8]}] {result['class_name']} ({result['confidence']:.1f}%) | ë°°ì¹˜:{len(jobs)} | {inference_time:.0f}ms")

                    # ë””ë²„ê·¸: í”„ë ˆì„ ì €ì¥ ë° ê¸°ë¡
                    if SAVE_DEBUG_FRAMES:
                        import cv2
                        timestamp_str = time.strftime("%H%M%S")
                        session_short = jobs[i].session_id[:8]

                        # ì²«ë²ˆì§¸, ì¤‘ê°„, ë§ˆì§€ë§‰ í”„ë ˆì„ ì €ì¥
                        frames = jobs[i].frames
                        for idx, frame_idx in enumerate([0, 14, 29]):
                            if frame_idx < len(frames):
                                frame = frames[frame_idx]
                                # RGB â†’ BGR for cv2
                                frame_bgr = cv2.cvtColor(frame, cv2.COLOR_RGB2BGR)
                                filename = f"{DEBUG_DIR}/{timestamp_str}_{session_short}_f{frame_idx}_{result['class_name']}.jpg"
                                cv2.imwrite(filename, frame_bgr)

                        # ì¶”ë¡  ê¸°ë¡ ì €ì¥
                        inference_record = {
                            "timestamp": time.strftime("%Y-%m-%d %H:%M:%S"),
                            "session_id": jobs[i].session_id[:8],
                            "class_id": result['class_id'],
                            "class_name": result['class_name'],
                            "confidence": result['confidence'],
                            "inference_time_ms": round(inference_time, 1),
                            "frame_count": len(frames),
                            "frame_shape": str(frames[0].shape) if frames else "N/A"
                        }
                        inference_history.append(inference_record)

                        # ìµœëŒ€ 100ê°œ ìœ ì§€
                        if len(inference_history) > 100:
                            inference_history.pop(0)

                # ê²°ê³¼ ì „ì†¡
                for i, job in enumerate(jobs):
                    result_data = {
                        "status": "inference_complete",
                        "session_id": job.session_id,
                        "result": results[i],
                        "batch_size": len(jobs),
                        "latency_ms": round((time.time() - job.timestamp) * 1000, 1)
                    }

                    # WebSocketìœ¼ë¡œ ì „ì†¡
                    if job.websocket:
                        try:
                            asyncio.run(job.websocket.send_json(result_data))
                        except:
                            pass

                    # HTTP í´ë§ìš© ì €ì¥
                    results_store[job.session_id] = result_data

            except Exception as e:
                print(f"âŒ Batch inference error: {e}")

# í”„ë ˆì„ ìˆ˜ì§‘ ë° í ì¶”ê°€
def add_frame_to_session(session_id: str, frame: np.ndarray, websocket=None):
    """í”„ë ˆì„ ì¶”ê°€ ë° 60í”„ë ˆì„ ë²„í¼ì—ì„œ ìµœì‹  30í”„ë ˆì„ìœ¼ë¡œ ì¶”ë¡ """
    with sessions_lock:
        if session_id not in user_sessions:
            user_sessions[session_id] = {
                'frames': [],
                'last_active': time.time(),
                'websocket': websocket
            }

        session = user_sessions[session_id]
        session['frames'].append(frame)
        session['last_active'] = time.time()
        if websocket:
            session['websocket'] = websocket

        buffer_size = len(session['frames'])

        # 60í”„ë ˆì„ ë²„í¼ê°€ ì°¨ë©´ ìµœì‹  30í”„ë ˆì„ìœ¼ë¡œ ì¶”ë¡ 
        if buffer_size >= FRAME_BUFFER_SIZE:
            job = InferenceJob(
                session_id=session_id,
                frames=session['frames'][-FRAMES_PER_INFERENCE:],  # ìµœì‹  30í”„ë ˆì„
                websocket=session.get('websocket'),
                timestamp=time.time()
            )
            inference_queue.put(job)

            # 10í”„ë ˆì„ ì‹œí”„íŠ¸ (ì¶”ë¡ ë‹¹ 33% ìƒˆ ë°ì´í„°)
            session['frames'] = session['frames'][FRAME_SHIFT:]

            return {
                "status": "queued",
                "buffer_size": len(session['frames']),
                "queue_size": inference_queue.qsize()
            }

        return {
            "status": "buffering",
            "buffer_size": buffer_size,
            "frames_needed": FRAMES_PER_INFERENCE - buffer_size
        }

@app.on_event("startup")
async def startup_event():
    """ì„œë²„ ì‹œì‘"""
    init_database()
    load_model()

    # GPU ë°°ì¹˜ ì›Œì»¤ ìŠ¤ë ˆë“œ ì‹œì‘
    worker_thread = threading.Thread(target=gpu_batch_worker, daemon=True)
    worker_thread.start()

@app.get("/health")
async def health_check():
    with sessions_lock:
        active_sessions = len(user_sessions)
        total_frames = sum(len(s['frames']) for s in user_sessions.values())

    return {
        "status": "healthy",
        "model_loaded": model is not None,
        "device": str(device),
        "active_sessions": active_sessions,
        "total_buffered_frames": total_frames,
        "inference_queue_size": inference_queue.qsize(),
        "batch_size": BATCH_SIZE,
        "batch_timeout_ms": BATCH_TIMEOUT * 1000
    }

# ==================== ë””ë²„ê·¸ API ====================

@app.get("/debug/inference")
async def debug_inference():
    """ìµœê·¼ ì¶”ë¡  ê¸°ë¡ ì¡°íšŒ"""
    import glob

    # ì €ì¥ëœ ë””ë²„ê·¸ ì´ë¯¸ì§€ ëª©ë¡
    debug_images = sorted(glob.glob(f"{DEBUG_DIR}/*.jpg"), key=os.path.getmtime, reverse=True)[:30]
    image_files = [os.path.basename(f) for f in debug_images]

    return {
        "total_inferences": len(inference_history),
        "recent_inferences": inference_history[-20:],  # ìµœê·¼ 20ê°œ
        "debug_images": image_files,
        "debug_dir": DEBUG_DIR,
        "save_enabled": SAVE_DEBUG_FRAMES
    }

@app.get("/debug/frame/{filename}")
async def get_debug_frame(filename: str):
    """ë””ë²„ê·¸ í”„ë ˆì„ ì´ë¯¸ì§€ ì¡°íšŒ"""
    file_path = os.path.join(DEBUG_DIR, filename)
    if os.path.exists(file_path):
        return FileResponse(file_path, media_type="image/jpeg")
    raise HTTPException(status_code=404, detail="Frame not found")

@app.delete("/debug/clear")
async def clear_debug():
    """ë””ë²„ê·¸ ë°ì´í„° ì´ˆê¸°í™”"""
    import glob
    for f in glob.glob(f"{DEBUG_DIR}/*.jpg"):
        os.remove(f)
    inference_history.clear()
    return {"status": "cleared", "message": "Debug data cleared"}

# ==================== ì¸ì¦ API ====================

@app.post("/auth/signup")
async def signup(request: SignUpRequest):
    conn = get_db_connection()
    cursor = conn.cursor()

    try:
        cursor.execute('SELECT id FROM users WHERE id = ?', (request.id,))
        if cursor.fetchone():
            conn.close()
            raise HTTPException(status_code=400, detail="ì´ë¯¸ ì¡´ì¬í•˜ëŠ” ì•„ì´ë””ì…ë‹ˆë‹¤")

        cursor.execute('''
            INSERT INTO users (id, name, password, address, region_name, region_campaign,
                             region_target, region_reward, score, discount_rate, created_at)
            VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)
        ''', (
            request.id, request.name, request.password, request.address,
            request.region_name, request.region_campaign, request.region_target,
            request.region_reward, 80, 0, time.strftime('%Y-%m-%d %H:%M:%S')
        ))

        conn.commit()
        conn.close()
        return {"success": True, "message": "íšŒì›ê°€ì…ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤"}

    except sqlite3.Error as e:
        conn.close()
        raise HTTPException(status_code=500, detail=f"DB ì˜¤ë¥˜: {str(e)}")

@app.post("/auth/login")
async def login(request: LoginRequest):
    conn = get_db_connection()
    cursor = conn.cursor()

    try:
        cursor.execute('SELECT * FROM users WHERE id = ?', (request.id,))
        user = cursor.fetchone()
        conn.close()

        if not user or user['password'] != request.password:
            raise HTTPException(status_code=401, detail="ì•„ì´ë”” ë˜ëŠ” ë¹„ë°€ë²ˆí˜¸ê°€ í‹€ë ¸ìŠµë‹ˆë‹¤")

        return {
            "success": True,
            "user": {
                "id": user['id'],
                "name": user['name'],
                "score": user['score'],
                "discount_rate": user['discount_rate'],
                "region": {
                    "name": user['region_name'],
                    "campaign": user['region_campaign'],
                    "target": user['region_target'],
                    "reward": user['region_reward'],
                    "address": user['address']
                }
            }
        }

    except sqlite3.Error as e:
        raise HTTPException(status_code=500, detail=f"DB ì˜¤ë¥˜: {str(e)}")

@app.get("/auth/user/{user_id}")
async def get_user(user_id: str):
    conn = get_db_connection()
    cursor = conn.cursor()

    cursor.execute('SELECT * FROM users WHERE id = ?', (user_id,))
    user = cursor.fetchone()
    conn.close()

    if not user:
        raise HTTPException(status_code=404, detail="ì‚¬ìš©ìë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤")

    return {
        "id": user['id'],
        "name": user['name'],
        "score": user['score'],
        "discount_rate": user['discount_rate'],
        "region": {
            "name": user['region_name'],
            "campaign": user['region_campaign'],
            "target": user['region_target'],
            "reward": user['region_reward'],
            "address": user['address']
        }
    }

# ==================== ìš´ì „ ê¸°ë¡ API ====================

@app.post("/driving/start")
async def start_driving(request: StartDrivingRequest):
    """ìš´ì „ ì‹œì‘ - ìƒˆ ìš´ì „ ê¸°ë¡ ìƒì„±"""
    conn = get_db_connection()
    cursor = conn.cursor()

    try:
        start_time = time.strftime('%Y-%m-%d %H:%M:%S')
        cursor.execute('''
            INSERT INTO driving_logs (user_id, start_time, status)
            VALUES (?, ?, 'driving')
        ''', (request.user_id, start_time))

        conn.commit()
        driving_log_id = cursor.lastrowid
        conn.close()

        return {
            "success": True,
            "driving_log_id": driving_log_id,
            "start_time": start_time
        }

    except sqlite3.Error as e:
        conn.close()
        raise HTTPException(status_code=500, detail=f"DB ì˜¤ë¥˜: {str(e)}")

@app.post("/driving/end")
async def end_driving(request: EndDrivingRequest):
    """ìš´ì „ ì¢…ë£Œ - ìš´ì „ ê¸°ë¡ ì—…ë°ì´íŠ¸"""
    conn = get_db_connection()
    cursor = conn.cursor()

    try:
        end_time = time.strftime('%Y-%m-%d %H:%M:%S')
        cursor.execute('''
            UPDATE driving_logs
            SET end_time = ?, status = 'completed'
            WHERE id = ?
        ''', (end_time, request.driving_log_id))

        conn.commit()
        conn.close()

        return {
            "success": True,
            "driving_log_id": request.driving_log_id,
            "end_time": end_time
        }

    except sqlite3.Error as e:
        conn.close()
        raise HTTPException(status_code=500, detail=f"DB ì˜¤ë¥˜: {str(e)}")

@app.post("/driving/detection")
async def save_detection(request: SaveDetectionRequest):
    """ëª¨ë¸ ê°ì§€ ê²°ê³¼ ì €ì¥"""
    conn = get_db_connection()
    cursor = conn.cursor()

    try:
        detected_at = time.strftime('%Y-%m-%d %H:%M:%S')

        # ê°ì§€ ê¸°ë¡ ì €ì¥
        cursor.execute('''
            INSERT INTO driving_detections (driving_log_id, detected_at, class_id, class_name, confidence)
            VALUES (?, ?, ?, ?, ?)
        ''', (request.driving_log_id, detected_at, request.class_id, request.class_name, request.confidence))

        # ìš´ì „ ê¸°ë¡ì˜ ì¹´ìš´íŠ¸ ì—…ë°ì´íŠ¸
        count_column = {
            0: 'normal_count',
            1: 'drowsy_count',
            2: 'searching_count',
            3: 'phone_count',
            4: 'assault_count'
        }.get(request.class_id, 'normal_count')

        cursor.execute(f'''
            UPDATE driving_logs
            SET total_detections = total_detections + 1,
                {count_column} = {count_column} + 1
            WHERE id = ?
        ''', (request.driving_log_id,))

        conn.commit()
        conn.close()

        return {"success": True, "detected_at": detected_at}

    except sqlite3.Error as e:
        conn.close()
        raise HTTPException(status_code=500, detail=f"DB ì˜¤ë¥˜: {str(e)}")

@app.get("/driving/logs/{user_id}")
async def get_driving_logs(user_id: str):
    """ì‚¬ìš©ìì˜ ëª¨ë“  ìš´ì „ ê¸°ë¡ ì¡°íšŒ"""
    conn = get_db_connection()
    cursor = conn.cursor()

    cursor.execute('''
        SELECT * FROM driving_logs
        WHERE user_id = ?
        ORDER BY start_time DESC
    ''', (user_id,))

    logs = cursor.fetchall()
    conn.close()

    return {
        "logs": [
            {
                "id": log['id'],
                "start_time": log['start_time'],
                "end_time": log['end_time'],
                "status": log['status'],
                "total_detections": log['total_detections'],
                "normal_count": log['normal_count'],
                "drowsy_count": log['drowsy_count'],
                "searching_count": log['searching_count'],
                "phone_count": log['phone_count'],
                "assault_count": log['assault_count']
            }
            for log in logs
        ]
    }

@app.get("/driving/log/{driving_log_id}")
async def get_driving_log_detail(driving_log_id: int):
    """íŠ¹ì • ìš´ì „ ê¸°ë¡ ìƒì„¸ ì¡°íšŒ (ê°ì§€ ê¸°ë¡ í¬í•¨)"""
    conn = get_db_connection()
    cursor = conn.cursor()

    # ìš´ì „ ê¸°ë¡ ì¡°íšŒ
    cursor.execute('SELECT * FROM driving_logs WHERE id = ?', (driving_log_id,))
    log = cursor.fetchone()

    if not log:
        conn.close()
        raise HTTPException(status_code=404, detail="ìš´ì „ ê¸°ë¡ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤")

    # ê°ì§€ ê¸°ë¡ ì¡°íšŒ
    cursor.execute('''
        SELECT * FROM driving_detections
        WHERE driving_log_id = ?
        ORDER BY detected_at ASC
    ''', (driving_log_id,))

    detections = cursor.fetchall()
    conn.close()

    return {
        "log": {
            "id": log['id'],
            "user_id": log['user_id'],
            "start_time": log['start_time'],
            "end_time": log['end_time'],
            "status": log['status'],
            "total_detections": log['total_detections'],
            "normal_count": log['normal_count'],
            "drowsy_count": log['drowsy_count'],
            "searching_count": log['searching_count'],
            "phone_count": log['phone_count'],
            "assault_count": log['assault_count']
        },
        "detections": [
            {
                "id": det['id'],
                "detected_at": det['detected_at'],
                "class_id": det['class_id'],
                "class_name": det['class_name'],
                "confidence": det['confidence']
            }
            for det in detections
        ]
    }

# ==================== ì„¸ì…˜/ì¶”ë¡  API ====================

@app.post("/session/create")
async def create_session():
    session_id = str(uuid.uuid4())
    with sessions_lock:
        user_sessions[session_id] = {
            'frames': [],
            'last_active': time.time(),
            'websocket': None
        }
    return {"session_id": session_id}

@app.delete("/session/{session_id}")
async def delete_session(session_id: str):
    with sessions_lock:
        if session_id in user_sessions:
            del user_sessions[session_id]
            return {"status": "deleted"}
    raise HTTPException(status_code=404, detail="Session not found")

@app.post("/infer")
async def infer(request: InferRequest):
    """í”„ë ˆì„ ì¶”ê°€ - 30í”„ë ˆì„ ë„ë‹¬ì‹œ ì¦‰ì‹œ íì— ì¶”ê°€"""
    try:
        frame = preprocess_image(request.image)
        result = add_frame_to_session(request.session_id, frame)
        return result
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))

@app.get("/result/{session_id}")
async def get_result(session_id: str):
    """ì¶”ë¡  ê²°ê³¼ í´ë§ (HTTPìš©)"""
    if session_id in results_store:
        return results_store.pop(session_id)
    return {"status": "pending"}

@app.websocket("/ws/{session_id}")
async def websocket_endpoint(websocket: WebSocket, session_id: str):
    """WebSocket ì‹¤ì‹œê°„ í†µì‹ """
    await websocket.accept()

    with sessions_lock:
        if session_id not in user_sessions:
            user_sessions[session_id] = {
                'frames': [],
                'last_active': time.time(),
                'websocket': websocket
            }
        else:
            user_sessions[session_id]['websocket'] = websocket

    try:
        while True:
            data = await websocket.receive_json()

            if data.get('type') == 'frame':
                try:
                    frame = preprocess_image(data['image'])
                    result = add_frame_to_session(session_id, frame, websocket)
                    await websocket.send_json(result)
                except Exception as e:
                    await websocket.send_json({"status": "error", "message": str(e)})

            elif data.get('type') == 'ping':
                await websocket.send_json({"type": "pong"})

    except WebSocketDisconnect:
        with sessions_lock:
            if session_id in user_sessions:
                user_sessions[session_id]['websocket'] = None
        print(f"WebSocket disconnected: {session_id}")

# ì„¸ì…˜ ì •ë¦¬
async def cleanup_sessions():
    while True:
        await asyncio.sleep(60)
        current_time = time.time()
        with sessions_lock:
            expired = [sid for sid, s in user_sessions.items() if current_time - s['last_active'] > 300]
            for sid in expired:
                del user_sessions[sid]
                if sid in results_store:
                    del results_store[sid]

@app.on_event("startup")
async def start_cleanup():
    asyncio.create_task(cleanup_sessions())

# ==================== í”„ë¡ íŠ¸ì—”ë“œ ì •ì  íŒŒì¼ ì„œë¹™ ====================

FRONTEND_DIR = "/root/ai-2026-c-team/driver_front/dist"

# ì •ì  íŒŒì¼ì´ ì¡´ì¬í•˜ë©´ ë§ˆìš´íŠ¸
if os.path.exists(FRONTEND_DIR):
    app.mount("/assets", StaticFiles(directory=f"{FRONTEND_DIR}/assets"), name="assets")

    @app.get("/{full_path:path}")
    async def serve_spa(full_path: str):
        """SPA fallback - ëª¨ë“  ê²½ë¡œë¥¼ index.htmlë¡œ"""
        # API ê²½ë¡œëŠ” ì œì™¸
        if full_path.startswith(("auth/", "driving/", "session/", "ws/", "health", "infer", "result/")):
            raise HTTPException(status_code=404)

        # ì •ì  íŒŒì¼ í™•ì¸
        file_path = os.path.join(FRONTEND_DIR, full_path)
        if os.path.isfile(file_path):
            return FileResponse(file_path)

        # SPA fallback
        return FileResponse(f"{FRONTEND_DIR}/index.html")

if __name__ == "__main__":
    uvicorn.run(app, host="0.0.0.0", port=8000)
